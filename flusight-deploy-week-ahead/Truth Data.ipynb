{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>location_long</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>AK</td>\n",
       "      <td>02</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>AZ</td>\n",
       "      <td>04</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>AR</td>\n",
       "      <td>05</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>California</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>CA</td>\n",
       "      <td>06</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>4/11/20</td>\n",
       "      <td>Washington</td>\n",
       "      <td>495.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>WA</td>\n",
       "      <td>53</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>4/11/20</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>WV</td>\n",
       "      <td>54</td>\n",
       "      <td>West Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>4/11/20</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>4/11/20</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>4/11/20</td>\n",
       "      <td>US</td>\n",
       "      <td>20463.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>nat</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  location_long    value  year  week  day state state_code  \\\n",
       "156   1/25/20        Alabama      0.0  2020     5    7    AL         01   \n",
       "157   1/25/20         Alaska      0.0  2020     5    7    AK         02   \n",
       "158   1/25/20        Arizona      0.0  2020     5    7    AZ         04   \n",
       "159   1/25/20       Arkansas      0.0  2020     5    7    AR         05   \n",
       "160   1/25/20     California      0.0  2020     5    7    CA         06   \n",
       "...       ...            ...      ...   ...   ...  ...   ...        ...   \n",
       "4207  4/11/20     Washington    495.0  2020    16    7    WA         53   \n",
       "4208  4/11/20  West Virginia      5.0  2020    16    7    WV         54   \n",
       "4209  4/11/20      Wisconsin    137.0  2020    16    7    WI         55   \n",
       "4210  4/11/20        Wyoming      0.0  2020    16    7    WY         56   \n",
       "4211  4/11/20             US  20463.0  2020    16    7   nat         US   \n",
       "\n",
       "         state_name  \n",
       "156         Alabama  \n",
       "157          Alaska  \n",
       "158         Arizona  \n",
       "159        Arkansas  \n",
       "160      California  \n",
       "...             ...  \n",
       "4207     Washington  \n",
       "4208  West Virginia  \n",
       "4209      Wisconsin  \n",
       "4210        Wyoming  \n",
       "4211            NaN  \n",
       "\n",
       "[624 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymmwr as pm\n",
    "import datetime\n",
    "\n",
    "\n",
    "def get_epi_data(date):\n",
    "    format_str = '%m/%d/%y'  # The format\n",
    "    dt = datetime.datetime.strptime(date, format_str).date()\n",
    "    epi = pm.date_to_epiweek(dt)\n",
    "    return epi.year, epi.week, epi.day\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\")\n",
    "fips_codes = pd.read_csv('../template/state_fips_codes.csv')\n",
    "\n",
    "\n",
    "# aggregate by state and nationally\n",
    "state_agg = df.groupby(['Province_State']).sum()\n",
    "us_nat = df.groupby(['Country_Region']).sum()\n",
    "df_state_nat = state_agg.append(us_nat)\n",
    "\n",
    "# drop unnecessary columns\n",
    "cols = list(range(0, 6))\n",
    "df_truth = df_state_nat.drop(df_state_nat.columns[cols], axis=1)\n",
    "\n",
    "# convert matrix to repeating row format\n",
    "df_truth = df_truth.unstack()\n",
    "df_truth = df_truth.reset_index()\n",
    "\n",
    "# get epi data from date\n",
    "df_truth['year'], df_truth['week'], df_truth['day'] = \\\n",
    "    zip(*df_truth['level_0'].map(get_epi_data))\n",
    "\n",
    "# rename columns\n",
    "df_truth = df_truth.rename(columns={0: \"value\",\n",
    "                                    \"level_1\": \"location_long\"})\n",
    "# Only visualize certain states\n",
    "states = ['US', 'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "          'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
    "          'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri',\n",
    "          'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "          'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island',\n",
    "          'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "          'West Virginia', 'Wisconsin', 'Wyoming', 'District of Columbia']\n",
    "df_truth = df_truth[df_truth[\"location_long\"].isin(states)]\n",
    "\n",
    "# Get state IDs\n",
    "df_truth = df_truth.merge(fips_codes, left_on='location_long', right_on='state_name', how='left')\n",
    "df_truth.loc[df_truth[\"location_long\"] == \"US\", \"state_code\"] = \"US\"\n",
    "df_truth[\"state_code\"].replace({\"US\": 1000}, inplace=True)  # so that can be converted to int\n",
    "\n",
    "# convert FIPS code to int\n",
    "df_truth[\"state_code\"] = df_truth[\"state_code\"].astype(int)\n",
    "\n",
    "# add leading zeros to state code\n",
    "df_truth['state_code'] = df_truth['state_code'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "\n",
    "# convert 1000 back to US\n",
    "df_truth[\"state_code\"].replace({\"1000\": \"US\"}, inplace=True)\n",
    "df_truth.loc[df_truth[\"location_long\"] == \"US\", \"state\"] = \"nat\"\n",
    "\n",
    "\n",
    "'''\n",
    "####################################\n",
    "# Daily truth data output for reference\n",
    "####################################\n",
    "'''\n",
    "\n",
    "# only output \"location\", \"epiweek\", \"value\"\n",
    "df_byday = df_truth.rename(columns={\"level_0\": \"date\", \"state_code\": \"location\", \"location_long\": \"location_name\"})\n",
    "\n",
    "# select columns\n",
    "df_byday = df_byday[[\"date\", \"location\", \"location_name\", \"value\"]]\n",
    "df_byday.to_csv('../data-processed/truth-cum-death.csv', index=False)\n",
    "\n",
    "'''\n",
    "####################################\n",
    "# Truth data output for visualization\n",
    "####################################\n",
    "'''\n",
    "# Observed data on the seventh day\n",
    "df_truth = df_truth[df_truth['day'] == 7]\n",
    "df_truth['week'] = df_truth['week'] + 1\n",
    "\n",
    "\n",
    "# add leading zeros to epi week\n",
    "df_truth['week'] = df_truth['week'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "\n",
    "# define epiweek\n",
    "df_truth['epiweek'] = df_truth['year'].astype(str) + df_truth['week']\n",
    "\n",
    "# only output \"location\", \"epiweek\", \"value\"\n",
    "df_truth = df_truth.rename(columns={\"state\": \"location\"})\n",
    "df_truth_short = df_truth[[\"location\", \"epiweek\", \"value\"]]\n",
    "\n",
    "df_truth_short[\"value\"].replace({0: 0.1}, inplace=True)\n",
    "\n",
    "# write to json\n",
    "with open('flusight-master/covid-csv-tools/dist/state_actual/2019.json', 'w') as f:\n",
    "    f.write(df_truth_short.to_json(orient='records'))\n",
    "\n",
    "\n",
    "'''\n",
    "####################################\n",
    "# Truth data output for Zoltar & Scoring\n",
    "####################################\n",
    "'''\n",
    "# rename location\n",
    "df_truth_long = df_truth.rename(columns={\"week\": \"epiweek\",\n",
    "                                         \"state_code\": \"unit\",\n",
    "                                         \"level_0\": \"date\"})\n",
    "# get timezero\n",
    "df_truth_long['date'] = pd.to_datetime(df_truth_long['date'])\n",
    "\n",
    "# find week-ahead targets\n",
    "for i in range(4):\n",
    "    weeks_ahead = i + 1\n",
    "    days_back = 5 + (weeks_ahead * 7)  # timezero is on Mondays\n",
    "\n",
    "    df_calc = df_truth_long  # initialize df\n",
    "\n",
    "    # find timezero and target\n",
    "    df_calc['timezero'] = df_calc['date'] - datetime.timedelta(days=days_back)\n",
    "    df_calc['target'] = \"%i_week_ahead_cum\" % weeks_ahead\n",
    "\n",
    "    # select columns\n",
    "    df_calc = df_calc[[\"timezero\", \"unit\", \"target\", \"value\"]]\n",
    "\n",
    "    # concatenate truth\n",
    "    if i == 0:\n",
    "        df_out = df_calc\n",
    "    else:\n",
    "        df_out = pd.concat([df_out, df_calc])\n",
    "\n",
    "# write truth to csv\n",
    "df_out.to_csv('../data-processed/zoltar-truth-cum-death.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
